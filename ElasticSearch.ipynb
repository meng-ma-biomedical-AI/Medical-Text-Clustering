{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import codecs\n",
    "import jieba\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import IndicesClient\n",
    "import mysql.connector as sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host':'localhost','port':9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_idx = IndicesClient(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_idx.delete(index='_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"acknowledged\":true,\"shards_acknowledged\":true,\"index\":\"main_idx\"}\n"
     ]
    }
   ],
   "source": [
    "a = os.popen('''\n",
    "curl -X PUT 'localhost:9200/main_idx' -d '\n",
    "{\n",
    "  \"mappings\": {\n",
    "    \"docs\": {\n",
    "      \"properties\": {\n",
    "        \"pure_text\": {\n",
    "          \"type\": \"text\",\n",
    "          \"analyzer\": \"ik_max_word\",\n",
    "          \"search_analyzer\": \"ik_max_word\"\n",
    "        },\n",
    "        \"processed_text\": {\n",
    "          \"type\": \"text\",\n",
    "          \"analyzer\": \"ik_max_word\",\n",
    "          \"search_analyzer\": \"ik_max_word\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}'\n",
    "''').read()\n",
    "for line in a.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_index\":\"main_idx\",\"_type\":\"docs\",\"_id\":\"1\",\"_version\":1,\"result\":\"created\",\"_shards\":{\"total\":2,\"successful\":1,\"failed\":0},\"created\":true}\n"
     ]
    }
   ],
   "source": [
    "# res1 = os.popen('''\n",
    "# curl -X PUT 'localhost:9200/main_idx/docs/1' -d '\n",
    "# {\n",
    "#     \"pure_text\": \"中华人民共和国国歌\",\n",
    "#     \"processed_text\": \"中华 人民 共和国 国歌\"\n",
    "# }'\n",
    "# ''').read()\n",
    "# for line in res1.split('\\n'):\n",
    "#     print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"took\":1,\"timed_out\":false,\"_shards\":{\"total\":5,\"successful\":5,\"skipped\":0,\"failed\":0},\"hits\":{\"total\":1,\"max_score\":0.25811607,\"hits\":[{\"_index\":\"main_idx\",\"_type\":\"docs\",\"_id\":\"1\",\"_score\":0.25811607,\"_source\":\n",
      "{\n",
      "    \"pure_text\": \"中华人民共和国国歌\",\n",
      "    \"processed_text\": \"中华 人民 共和国 国歌\"\n",
      "}}]}}\n"
     ]
    }
   ],
   "source": [
    "# res = os.popen('''\n",
    "# curl 'localhost:9200/main_idx/docs/_search'  -d '\n",
    "# {\n",
    "#   \"query\" : { \"match\" : { \"pure_text\" : \"中华人民共和国\" }}\n",
    "# }'\n",
    "# ''').read()\n",
    "# for line in res.split('\\n'):\n",
    "#     print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_idx.exists(index='main_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_question:  1970\n",
      "all_question:  1656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.487 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Description</th>\n",
       "      <th>KeyWords</th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1420656.0</td>\n",
       "      <td>赫赛汀  配了之后结冰了， 能否继续使用。</td>\n",
       "      <td>使用 赫赛汀</td>\n",
       "      <td>赫赛汀  配  之后  结冰  继续  使用</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1423956.0</td>\n",
       "      <td>赫赛汀粉末形状如何？患者保存的赫赛汀的稀释液出现结冰情况，是否能否使用</td>\n",
       "      <td>无 使用 患者 赫赛汀</td>\n",
       "      <td>赫赛汀  粉末  形状  保存  赫赛汀  稀释  稀释液  出现  结冰  冰情  情况 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1434184.0</td>\n",
       "      <td>请帮忙查一些赫赛汀与血栓栓塞方面的数据和文献</td>\n",
       "      <td>栓塞 查 赫赛汀 文献 血栓栓塞 无 血栓</td>\n",
       "      <td>帮忙  查  赫赛汀  血栓  血栓栓塞  栓塞  方面  数据  和文  文献</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1436011.0</td>\n",
       "      <td>拿到的赫赛汀呈现块状是否正常</td>\n",
       "      <td>正常 赫赛汀</td>\n",
       "      <td>拿到  赫赛汀  呈现  块状  是否  正常</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1438071.0</td>\n",
       "      <td>常规配置和保存的赫赛汀复溶后的溶液保存在2-8度的情况下，现出现浑浊情况，能否使用</td>\n",
       "      <td>赫赛汀 配置 现 下 溶液 使用</td>\n",
       "      <td>常规  配置  保存  赫赛汀  复  溶  溶液  保存  存在  2  8  度  情况...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case Number                                Description  \\\n",
       "0    1420656.0                      赫赛汀  配了之后结冰了， 能否继续使用。   \n",
       "1    1423956.0        赫赛汀粉末形状如何？患者保存的赫赛汀的稀释液出现结冰情况，是否能否使用   \n",
       "2    1434184.0                     请帮忙查一些赫赛汀与血栓栓塞方面的数据和文献   \n",
       "3    1436011.0                             拿到的赫赛汀呈现块状是否正常   \n",
       "4    1438071.0  常规配置和保存的赫赛汀复溶后的溶液保存在2-8度的情况下，现出现浑浊情况，能否使用   \n",
       "\n",
       "                KeyWords                                          Processed  \n",
       "0                 使用 赫赛汀                             赫赛汀  配  之后  结冰  继续  使用  \n",
       "1            无 使用 患者 赫赛汀  赫赛汀  粉末  形状  保存  赫赛汀  稀释  稀释液  出现  结冰  冰情  情况 ...  \n",
       "2  栓塞 查 赫赛汀 文献 血栓栓塞 无 血栓           帮忙  查  赫赛汀  血栓  血栓栓塞  栓塞  方面  数据  和文  文献  \n",
       "3                 正常 赫赛汀                            拿到  赫赛汀  呈现  块状  是否  正常  \n",
       "4       赫赛汀 配置 现 下 溶液 使用  常规  配置  保存  赫赛汀  复  溶  溶液  保存  存在  2  8  度  情况...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_question = pd.read_csv('./data/description.csv')\n",
    "Herceptin_question = pd.read_excel('./data/Herceptin.xlsx')\n",
    "# all_question = pd.read_excel('./data/Herceptin_funding_filtered.xlsx')\n",
    "# all_question = pd.read_excel('./data/Herceptin_patient_filtered.xlsx')\n",
    "Kadcyla_question = pd.read_excel('./data/Kadcyla.xlsx')\n",
    "Perjeta_1_question = pd.read_excel('./data/Perjeta_1.xlsx')\n",
    "Perjeta_2_question = pd.read_excel('./data/Perjeta_2.xlsx')\n",
    "Tecentriq_question = pd.read_excel('./data/Tecentriq.xlsx')\n",
    "Xeloda_question = pd.read_excel('./data/Xeloda.xlsx')\n",
    "No_product_question = pd.read_excel('./data/No_product_merged.xlsx')\n",
    "\n",
    "all_question = pd.concat([Herceptin_question, Kadcyla_question, Perjeta_1_question, Perjeta_2_question, Tecentriq_question, Xeloda_question, No_product_question])\n",
    "print('all_question: ', len(all_question))\n",
    "all_question.head(5)\n",
    "\n",
    "all_question.dropna(axis=0, inplace=True, subset=['Description'])\n",
    "all_question.isna().sum()\n",
    "\n",
    "print('all_question: ', len(all_question))\n",
    "\n",
    "jieba.load_userdict('./dict data/chinese_word_dict.txt')\n",
    "chinese_word_dict = pickle.load(open('./dict data/chinese_word_dict.pickle', 'rb'))\n",
    "stopwords = [line.strip() for line in codecs.open('./stopwords-zh.txt', 'r', encoding='utf8').readlines()]\n",
    "\n",
    "def keyword_extract(text, word_dict):\n",
    "#     text = list(jieba.cut(text, cut_all=False))\n",
    "    text = list(jieba.cut_for_search(text))\n",
    "    union_text = list(set(text).intersection(set(word_dict)))\n",
    "    return \" \".join(union_text)\n",
    "\n",
    "all_question['KeyWords'] = all_question.Description.apply(lambda x: keyword_extract(x, chinese_word_dict))\n",
    "\n",
    "# 去除所有“[]”内的文本\n",
    "def remove_special_string(text):\n",
    "    text = re.sub(r'\\[[^]]*\\]', '', text)\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'（[^）]*\\）', '', text)\n",
    "    text = re.sub(r'\\<[^>]*\\>', '', text)\n",
    "#     text = re.sub(r'[0-9]*', '', text)\n",
    "#     text = re.sub('患者', '', text)\n",
    "#     text = re.sub('家属', '', text)\n",
    "#     text = re.sub('咨询', '', text)\n",
    "#     text = re.sub('询问', '', text)\n",
    "    return text\n",
    "def remove_stopwords(text, stopwords):\n",
    "    text_cutted = jieba.cut(text, cut_all=True)\n",
    "    text_removed = []\n",
    "    for word in text_cutted:\n",
    "        if word in stopwords or word.strip()==\"\":\n",
    "            continue\n",
    "        text_removed.append(word)\n",
    "    return \"  \".join(text_removed)\n",
    "\n",
    "all_question['Description'] = all_question.Description.apply(lambda x: remove_special_string(x))\n",
    "all_question['Processed'] = all_question.Description.apply(lambda x: remove_special_string(x))\n",
    "all_question['Processed'] = all_question.Processed.apply(lambda x: remove_stopwords(x, stopwords))\n",
    "all_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_query_text = []\n",
    "for idx, row in all_question.iterrows():\n",
    "    all_query_text.append(str(row['Description']) + \"\\n\\n\")\n",
    "    \n",
    "# all_query_text_f = open('all_query_text.txt', 'w')\n",
    "# all_query_text_f.writelines(all_query_text)\n",
    "# all_query_text_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656\n",
      "{'pure_text': '赫赛汀  配了之后结冰了， 能否继续使用。', 'processed_text': '赫赛汀 使用'}\n"
     ]
    }
   ],
   "source": [
    "doc_list = []\n",
    "for idx,row in all_question.iterrows():\n",
    "    doc = {\"pure_text\": row['Description'], \"processed_text\": row['KeyWords']}\n",
    "    doc_list.append(doc)\n",
    "print(len(doc_list))\n",
    "print(doc_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_index\":\"main_idx\",\"_type\":\"docs\",\"_id\":\"AWtKqYf1nL1wRDg7tQ3N\",\"_version\":1,\"result\":\"created\",\"_shards\":{\"total\":2,\"successful\":1,\"failed\":0},\"created\":true}\n"
     ]
    }
   ],
   "source": [
    "res1 = os.popen('''\n",
    "curl -X POST 'localhost:9200/main_idx/docs' -d '\n",
    "{\n",
    "    \"pure_text\": \"您好，请帮忙查一下数据，谢谢！需要绝经后女性乳腺癌的以下各项指标的比例。ER阳性，PR阳性，AR，HER2阳性，LuminalA，LuminalB，三阴性。感谢，盼复。\",\n",
    "    \"processed_text\": \"您好 ， 请 帮忙 查 一下 数据 ，谢谢 ！ 需要 绝经 后 女性 乳腺癌 的 以下 各项 指标 的 比例 。ER 阳性 ， PR 阳性 ， AR，HER2 阳性 ， LuminalA ， LuminalB ， 三阴性 。 感谢 ， 盼复 。 \"\n",
    "}'\n",
    "''').read()\n",
    "for line in res1.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [01:54<00:00, 14.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(doc_list):\n",
    "    temp = os.popen('''\n",
    "    curl -X POST 'localhost:9200/main_idx/docs' -d '\n",
    "    {}\n",
    "    '\n",
    "    '''.format(str(doc).replace(\"\\\"\", \"\\'\").replace(\"\\'\", \"\\\"\"))).read()\n",
    "#     for line in temp.split('\\n'):\n",
    "#         print(line)\n",
    "        \n",
    "#     print('''\n",
    "#     curl -X PUT 'localhost:9200/ik_test/docs/{}' -d '\n",
    "#     {}\n",
    "#     '\n",
    "#     '''.format(str(idx), str(doc_list[idx]).replace(\"\\\"\", \"\\'\").replace(\"\\'\", \"\\\"\")))\n",
    "    \n",
    "# curl -X PUT 'localhost:9200/ik_test/docs/1' -d '\n",
    "# {\n",
    "#     \"content\": \"中华人民共和国国歌\"\n",
    "# }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = os.popen('''\n",
    "curl 'localhost:9200/main_idx/docs/_search?pretty=true'  -d '\n",
    "{\n",
    "  \"query\" : { \"match\" : { \"processed_text\" : \"关于赫赛汀心脏毒性：1、临床 2、临床前\" }}\n",
    "}'\n",
    "''').read()\n",
    "for line in res.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(doc_list)):\n",
    "    es.index(index='text_search', id=idx, body=doc_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"乳腺癌\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  肿瘤浸润迁移是乳腺癌治疗失败的根本原因，抑制肿瘤迁移是提高乳腺癌疗效的关键。课题组前期研究证明肿瘤微环境中TAM来源的CCL18通过其受体PITPNM3促进乳腺癌浸润迁移。进一步研究证明CCL18激活乳腺癌上皮间质转化（EMT）信号通路，促进肿瘤EMT。MicroRNAs调控肿瘤多种生物学功能,但microRNAs对CCL18促乳腺癌EMT的调控作用还未阐明。本课题将研究CCL18激活的乳腺癌EMT信号通路通过激活其它信号分子、转录因子调控CCL18相关microRNAs的表达；CCL18相关microRNAs靶向乳腺癌EMT信号通路，维持EMT信号通路激活，调控CCL18促乳腺癌EMT，调控乳腺癌浸润、迁移。在乳腺癌组织中，证明CCL18相关microRNAs调控乳腺癌EMT，与肿瘤的预后、转移相关。为抑制乳腺癌转移提供新的治疗靶点，开辟乳腺癌治疗新途径。\n",
      "2:  乳腺癌是与雌激素等多病因相关的复杂疾病。镉是一种类雌激素，已被证实与乳腺癌相关，可能导致部分乳腺癌，但究竟导致哪些临床病理类型的乳腺癌，以及与人群的遗传易感特征有何关系，未有报道。本项目采用单纯病例研究方法，利用我们已建立的乳腺癌病例对照研究人群中的病例组（1100例），在考虑乳腺癌传统危险因素基础上，采用病例-系列研究方法分析高与低尿镉乳腺癌在发病年龄、临床分期、病理类型和免疫组化标记ER、PR和HER2等特征上的分布差异，获得镉致乳腺癌的临床病理特征；再检测与镉运输和代谢等密切相关的金属硫蛋白各亚型基因和雌激素受体α基因的多态性，采用病例-病例研究方法分析其与尿镉的交互作用，获得对镉敏感乳腺癌的遗传易感标记，从而为揭示镉致乳腺癌机制提供线索，为采取更针对性的乳腺癌防治措施提供依据。\n",
      "3:  BRCA1和BRCA2基因致病性突变是目前公认的预测乳腺癌发病风险的重要因素。其突变率及突变位点对发病风险有影响。中国乳腺癌不仅在发病率、发病年龄异于西方，本课题组的前期工作表明中国乳腺癌在BRCA1/2突变率及突变位点也与西方有较大差异。精准的预测乳腺癌高危人群的发病风险能推动乳腺癌的预防和早诊，具有降低乳腺癌发病率和死亡率的重要作用。本项目基于国内较大宗的家族性乳腺癌BRCA1/2基因突变全编码区测序检测，检测家族性乳癌患者及其一级女性亲属的BRCA1/2突变情况，结合中国汉族女性乳腺癌患者的家族史等个人信息、临床病理资料，用统计学方法筛选出在有乳腺癌家族史的中国汉族妇女中有意义的乳腺癌风险因子，明确有乳腺癌家族史的中国健康汉族妇女在不同BRCA1/2基因状态下乳腺癌发病的年龄累积风险，从而更好的指导中国汉族妇女预防、早诊和治疗乳腺癌。\n",
      "4:  乳腺癌的转移性复发是引起乳腺癌患者死亡的首要原因。大量研究表明阿片类药物之一芬太尼能诱发乳腺癌的转移性复发，增加了乳腺癌患者术后死亡率，但芬太尼导致乳腺癌复发的作用机制不清。本课题拟在前期研究的基础上，①检测芬太尼对乳腺癌患者外周血中调节T细胞数目和功能影响；②在大鼠乳腺癌模型中检测芬太尼对调节性T细胞数目和功能影响的时间剂量关系以及对乳腺癌细胞转移的影响；③检测芬太尼能否直接作用于调节性T细胞各亚型，影响其功能（特别是TGF-beta的表达）及其相关的信号通路；④检测TGF-beta对乳腺癌细胞侵袭力的影响及其机制；⑤用乳腺癌患者的调节性T细胞亚型和乳腺癌细胞共同培养，验证芬太尼在大鼠乳腺癌模型中的作用及机制。以期阐明芬太尼影响乳腺癌转移性复发的具体机制，为围手术期降低乳腺癌的转移性复发提供理论依据。\n",
      "5:  乳腺癌严重危害女性健康，线粒体蛋白在乳腺癌发生发展中的作用报道很少，其与乳腺癌转移的研究报道更少。我们前期工作首次发现，线粒体蛋白TMEM126A在转移能力强的乳腺癌细胞中低表达，而过表达TMEM126A能显著降低细胞的迁移能力。前期结果提示，TMEM126A可能在抑制乳腺癌转移方面发挥重要作用。本项目拟深入研究TMEM126A降低乳腺癌转移的具体机制，找出TMEM126A调控的可能信号通路；探索TMEM126A与乳腺癌转移，病人生存率，预后等指标之间的临床规律。本项目有助于进一步解析线粒体蛋白与乳腺癌转移的关系，促进从线粒体蛋白寻找乳腺癌生物标志物的研究；为乳腺癌的临床治疗提供新思路，对于指导临床治疗乳腺癌具有实际的应用价值。\n",
      "6:  乳腺癌是女性最常见恶性肿瘤之一，乳腺癌易发生隐匿性转移是乳腺癌患者的主要致死原因。课题组前期研究表明: TGF-β在乳腺癌细胞中可通过PI3K/Akt通路诱导Pokemon的表达，在乳腺癌细胞中Pokemon对E-cadherin的表达存在负性调控作用，而乳腺癌淋巴结转移与Pokemon的高表达呈正相关。目前Pokemon在乳腺癌转移过程中的作用及机制尚不明确。本课题拟揭示Pokemon 对乳腺癌细胞侵袭转移能力和乳腺癌上皮间质化的影响，阐明Pokemon促进乳腺癌发生侵袭转移的作用机制，分析在乳腺癌中Pokemon、E-cadherin 和Fibronectin 等表达的相关性，并探讨其是否与乳腺癌发生、转移和预后相关。本课题的完成将能明确TGF-β-PI3K/Akt -Pokemon - E-cadherin通路在乳腺癌上皮间质转化和侵袭转移中的作用，可为乳腺癌防治提供新的思路。\n",
      "7:  乳腺癌是我国女性最常见的恶性肿瘤，本研究拟通过以300例散发性乳腺癌患者及100例家族性乳腺癌患者为研究对象，对核苷酸切除修复途径中识别DNA损伤的着色性干皮病基因A单核甘酸多态性位点进行病例对照的关联分析和研究。采用荧光定量PCR技术检测XPA -4G/A基因多态性，确定我国人群中乳腺癌患者的基因型分布，同时，对乳腺癌相关基因BRCA1/2的突变情况进行分析，结合发病年龄及婚育史等因素，研究XPA -4G/A基因多态性与乳腺癌易感性之间的联系，综合评价该基因多态性对乳腺癌易感性的影响；并通过比较散发性乳腺癌和家族性乳腺癌的易感性程度，为乳腺癌高危人群筛查和针对病因制定预防措施提供科学依据。\n",
      "8:  乳腺癌骨转移是影响乳腺癌预后的主要原因之一，但其机制仍不明确。RANKL/RANK通路是破骨细胞分化及活化的经典通路，近年来该通路介导的肿瘤细胞的转移愈来愈受到研究者的关注。本研究旨在明确RANKL/RANK通路是否能够介导乳腺癌骨转移，泛素连接酶Cbl-b能否调节RANKL/RANK介导的乳腺癌骨转移。我们的研究证实：1.RANKL能够诱导乳腺癌细胞迁移，RANK阳性乳腺癌患者的无骨转移生存时间明显缩短；2.c-Src、Gab2和PI3K/Akt等的活化是影响RANKL诱导的乳腺癌细胞迁移的关键因素，c-Src抑制剂PP2，PI3K 抑制剂LY294002等能显著抑制RANKL诱导乳腺癌细胞的迁移；3.Cbl-b参与调控RANKL诱导的乳腺癌迁移，抑制Cbl-b的表达通过增强RANKL诱导c-Src活化，促进RANKL诱导的乳腺癌细胞的迁移；4.Cbl对PI3K/Akt及ERK通路的抑制作用也可见于其他细胞。上述研究证实我们的假说：RANKL/RANK能够介导乳腺癌骨转移，Cbl-b能调节RANKL/RANK介导的乳腺癌迁移。本研究结果为解明乳腺癌骨转移机制提供了进一步的科学论据。\n",
      "9:  最新研究表明FGFR2是乳腺癌易感基因，其高表达导致乳腺癌，且与环境因素产生交互作用而影响乳腺癌发生发展；我们在乳腺癌病人中发现尿镉与血白细胞FGFR2基因5端甲基化水平相关，而甲基化改变会影响其基因表达。故此，我们推测FGFR2甲基化水平与乳腺癌相关并受镉等环境因素的影响。本项目先利用我们已建立的乳腺癌病例对照（各800例）人群，分析血DNA中FGFR2基因多态性、甲基化及尿镉等环境因素的相互关系，及其单独与交互作用对乳腺癌发病风险影响；再比较乳腺癌和癌旁组织（90对）中镉含量及FGFR2甲基化与表达（mRNA和蛋白）差异及各指标间的相关性；最后用细胞生物学方法，进一步探讨镉是否通过影响FGFR2甲基化而改变其表达再导致乳腺癌，从而获得乳腺癌特征性生物标记，为阐明FGFR2及镉等环境因素参与乳腺癌发病机制提供线索，也为乳腺癌预防、治疗和新药开发等提供参考依据。\n",
      "10:  转移相关基因对转移的调控是乳腺癌发生转移的分子基础，发现新的乳腺癌转移相关基因并阐明其作用机制将为转移性乳腺癌的分子诊断和个体化治疗奠定基础。hPEBP4是本课题组自主克隆的新型磷脂酰乙醇胺结合蛋白（GenBank登录号AY037148，国家发明专利号ZL 02136556.3)，表达高低和乳腺癌、前列腺癌的恶性程度正相关，而其表达下调增强肿瘤细胞对抗肿瘤药物的敏感性。我们前期结果显示hPEBP4高表达于乳腺癌转移灶，以及高转移的乳腺癌细胞系,并促进乳腺癌细胞系的转移。拟在此基础上通过体内、体外实验确定hPEBP4在乳腺癌转移中的作用，并探讨其作用机制。同时研究临床标本中hPEBP4表达高低与乳腺癌转移的关系。该项目的完成可进一步揭示hPEBP4分子的生理、病理功能以及其与乳腺癌的生物学行为的关系。并探讨其作为乳腺癌治疗基因靶点的可能性，为转移性乳腺癌的治疗提供新的思路。\n"
     ]
    }
   ],
   "source": [
    "# processed_text  pure_text\n",
    "results = es.search(index='main_idx', body=\n",
    "{\n",
    "  \"query\" : { \"match\" : { \"pure_text\" : query }}\n",
    "}\n",
    "# {\n",
    "#   \"query\": {\n",
    "#     \"bool\": {\n",
    "#       \"must\":     { \"match\": { \"processed_text\": query }},\n",
    "#       \"should\":   { \"match\": { \"pure_text\": \"帕妥珠单抗\" }}\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    ",size=10)\n",
    "hits = results['hits']['hits']\n",
    "# results\n",
    "for idx, res in enumerate(hits):\n",
    "#     if \"帕妥珠单抗\" in res['_source']['pure_text']:\n",
    "    print(str(idx+1) + \":  \" + res['_source']['pure_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "乳腺癌激酶\n",
      "用于\n",
      "治疗\n",
      "乳腺癌\n",
      "一种\n",
      "激酶\n"
     ]
    }
   ],
   "source": [
    "tokens_res = es_idx.analyze(index='main_idx', body={\n",
    "#     \"analyzer\": \"ik_max_word\",\n",
    "    \"analyzer\": \"ik_smart\",\n",
    "    \"text\" : \"乳腺癌激酶是用于治疗乳腺癌的一种激酶\"\n",
    "})\n",
    "for token in tokens_res['tokens']:\n",
    "    print(token['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
