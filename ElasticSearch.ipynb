{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "import jieba\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host':'localhost','port':9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_question = pd.read_csv('./data/description.csv')\n",
    "all_question = pd.read_excel('./data/Herceptin.xlsx')\n",
    "# all_question = pd.read_excel('./data/Herceptin_funding_filtered.xlsx')\n",
    "# all_question = pd.read_excel('./data/Herceptin_patient_filtered.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_question.dropna(axis=0, inplace=True, subset=['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number    0\n",
       "Description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_question.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict('./chinese_word_dict.txt')\n",
    "chinese_word_dict = pickle.load(open('./chinese_word_dict.pickle', 'rb'))\n",
    "stopwords = [line.strip() for line in codecs.open('./stopwords-zh.txt', 'r', encoding='utf8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_extract(text, word_dict):\n",
    "#     text = list(jieba.cut(text, cut_all=False))\n",
    "    text = list(jieba.cut_for_search(text))\n",
    "    union_text = list(set(text).intersection(set(word_dict)))\n",
    "    return \" \".join(union_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_question['KeyWords'] = all_question.Description.apply(lambda x: keyword_extract(x, chinese_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除所有“[]”内的文本\n",
    "def remove_special_string(text):\n",
    "    text = re.sub(r'\\[[^]]*\\]', '', text)\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'（[^）]*\\）', '', text)\n",
    "    text = re.sub(r'\\<[^>]*\\>', '', text)\n",
    "    text = re.sub(r'[0-9]*', '', text)\n",
    "    return text\n",
    "def remove_stopwords(text, stopwords):\n",
    "    text_cutted = jieba.cut(text, cut_all=True)\n",
    "    text_removed = []\n",
    "    for word in text_cutted:\n",
    "        if word in stopwords or word.strip()==\"\":\n",
    "            continue\n",
    "        text_removed.append(word)\n",
    "    return \"  \".join(text_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Description</th>\n",
       "      <th>KeyWords</th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1420656.0</td>\n",
       "      <td>赫赛汀 （批号1： N3825B03B3049, 批号2： N3826B02B3050） 配...</td>\n",
       "      <td>赫赛汀 使用</td>\n",
       "      <td>配  之后  结冰  继续  使用</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1423956.0</td>\n",
       "      <td>赫赛汀粉末形状如何？患者保存的赫赛汀的稀释液出现结冰情况，是否能否使用（无产品批号信息）</td>\n",
       "      <td>无 赫赛汀 患者 使用</td>\n",
       "      <td>粉末  形状  保存  稀释  稀释液  出现  结冰  冰情  情况  是否  使用</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1434184.0</td>\n",
       "      <td>[Wechat] 请帮忙查一些赫赛汀与血栓栓塞方面的数据和文献（确认无AE）</td>\n",
       "      <td>文献 血栓栓塞 赫赛汀 查 栓塞 血栓 无</td>\n",
       "      <td>帮忙  查  血栓  血栓栓塞  栓塞  方面  数据  和文  文献</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1436011.0</td>\n",
       "      <td>拿到的赫赛汀呈现块状是否正常</td>\n",
       "      <td>赫赛汀 正常</td>\n",
       "      <td>拿到  呈现  块状  是否  正常</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1438071.0</td>\n",
       "      <td>常规配置和保存的赫赛汀复溶后的溶液保存在2-8度的情况下，现出现浑浊情况，能否使用</td>\n",
       "      <td>溶液 赫赛汀 配置 现 使用 下</td>\n",
       "      <td>常规  配置  保存  复  溶  溶液  保存  存在  度  情况  现出  出现  浑...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case Number                                        Description  \\\n",
       "0    1420656.0  赫赛汀 （批号1： N3825B03B3049, 批号2： N3826B02B3050） 配...   \n",
       "1    1423956.0       赫赛汀粉末形状如何？患者保存的赫赛汀的稀释液出现结冰情况，是否能否使用（无产品批号信息）   \n",
       "2    1434184.0             [Wechat] 请帮忙查一些赫赛汀与血栓栓塞方面的数据和文献（确认无AE）   \n",
       "3    1436011.0                                     拿到的赫赛汀呈现块状是否正常   \n",
       "4    1438071.0          常规配置和保存的赫赛汀复溶后的溶液保存在2-8度的情况下，现出现浑浊情况，能否使用   \n",
       "\n",
       "                KeyWords                                          Processed  \n",
       "0                 赫赛汀 使用                                  配  之后  结冰  继续  使用  \n",
       "1            无 赫赛汀 患者 使用        粉末  形状  保存  稀释  稀释液  出现  结冰  冰情  情况  是否  使用  \n",
       "2  文献 血栓栓塞 赫赛汀 查 栓塞 血栓 无                帮忙  查  血栓  血栓栓塞  栓塞  方面  数据  和文  文献  \n",
       "3                 赫赛汀 正常                                 拿到  呈现  块状  是否  正常  \n",
       "4       溶液 赫赛汀 配置 现 使用 下  常规  配置  保存  复  溶  溶液  保存  存在  度  情况  现出  出现  浑...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_question['Processed'] = all_question.Description.apply(lambda x: remove_special_string(x))\n",
    "all_question['Processed'] = all_question.Processed.apply(lambda x: remove_stopwords(x, stopwords))\n",
    "all_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757\n",
      "{'text': '赫赛汀 （批号1：\\xa0N3825B03B3049, 批号2： N3826B02B3050） 配了之后结冰了， 能否继续使用。', 'processed_text': '配  之后  结冰  继续  使用'}\n"
     ]
    }
   ],
   "source": [
    "doc_list = []\n",
    "for idx,row in all_question.iterrows():\n",
    "    doc = {\"text\": row['Description'], \"processed_text\": row['Processed']}\n",
    "    doc_list.append(doc)\n",
    "print(len(doc_list))\n",
    "print(doc_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(doc_list)):\n",
    "    es.index(index='index', doc_type='type', id=idx, body=doc_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 7,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 726, 'relation': 'eq'},\n",
       "  'max_score': 62.157417,\n",
       "  'hits': [{'_index': 'index',\n",
       "    '_type': 'type',\n",
       "    '_id': '510',\n",
       "    '_score': 62.157417,\n",
       "    '_source': {'text': '关于赫赛汀心脏毒性：1、临床 2、临床前',\n",
       "     'processed_text': '心脏  心脏毒性  脏毒  毒性  临床  临床  前'}},\n",
       "   {'_index': 'index',\n",
       "    '_type': 'type',\n",
       "    '_id': '620',\n",
       "    '_score': 38.22045,\n",
       "    '_source': {'text': '[Wechat] 临床上赫赛汀q3W和qW用法，在心脏毒性方面，哪个频率心脏毒性小些？相关研究？',\n",
       "     'processed_text': '临床  床上  qW  qW  用法  心脏  心脏毒性  脏毒  毒性  方面  频率  心脏  心脏毒性  脏毒  毒性  相关  研究'}},\n",
       "   {'_index': 'index',\n",
       "    '_type': 'type',\n",
       "    '_id': '501',\n",
       "    '_score': 21.81059,\n",
       "    '_source': {'text': '[Wechat] 赫赛汀抑制二聚体形成的临床研究',\n",
       "     'processed_text': '抑制  二聚体  体形  形成  临床  临床研究  研究'}},\n",
       "   {'_index': 'index',\n",
       "    '_type': 'type',\n",
       "    '_id': '667',\n",
       "    '_score': 21.803432,\n",
       "    '_source': {'text': '[Wechat] 赫赛汀对于心脏毒性的相关文献以及处理方法',\n",
       "     'processed_text': '心脏  心脏毒性  脏毒  毒性  相关  关文  关文献  文献  处理  处理方法  方法'}},\n",
       "   {'_index': 'index',\n",
       "    '_type': 'type',\n",
       "    '_id': '284',\n",
       "    '_score': 21.691664,\n",
       "    '_source': {'text': '[Wechat] 赫赛汀，放疗，心脏毒性相关文献',\n",
       "     'processed_text': '放疗  心脏  心脏毒性  脏毒  毒性  性相  相关  关文  关文献  文献'}},\n",
       "   {'_index': 'index',\n",
       "    '_type': 'type',\n",
       "    '_id': '408',\n",
       "    '_score': 18.197977,\n",
       "    '_source': {'text': '赫赛汀在心脏毒性方面的研究数据',\n",
       "     'processed_text': '心脏  心脏毒性  脏毒  毒性  方面  研究  数据'}},\n",
       "   {'_index': 'index',\n",
       "    '_type': 'type',\n",
       "    '_id': '621',\n",
       "    '_score': 16.732822,\n",
       "    '_source': {'text': '使用赫赛汀治疗过程中对心脏毒性方面的文献',\n",
       "     'processed_text': '使用  治疗  过程  心脏  心脏毒性  脏毒  毒性  方面  文献'}},\n",
       "   {'_index': 'index',\n",
       "    '_type': 'type',\n",
       "    '_id': '66',\n",
       "    '_score': 16.651888,\n",
       "    '_source': {'text': '临床医生提出患者把赫赛汀冷冻了，请问是否能继续使用？是否有官方数据来支持',\n",
       "     'processed_text': '临床  提出  冷冻  请问  是否  继续  使用  是否  官方  数据  支持'}},\n",
       "   {'_index': 'index',\n",
       "    '_type': 'type',\n",
       "    '_id': '569',\n",
       "    '_score': 16.326431,\n",
       "    '_source': {'text': '烦请帮忙查询\\xa0赫赛汀心脏毒性报道，相关文献\\xa0请帮忙查询相关文献及幻灯片。谢谢，辛苦了！',\n",
       "     'processed_text': '烦请  帮忙  查询  心脏  心脏毒性  脏毒  毒性  报道  相关  关文  关文献  文献  帮忙  查询  相关  关文  关文献  文献  幻灯  幻灯片  辛苦'}},\n",
       "   {'_index': 'index',\n",
       "    '_type': 'type',\n",
       "    '_id': '720',\n",
       "    '_score': 15.97923,\n",
       "    '_source': {'text': '[Wechat] 对于晚期病人长期使用赫赛汀至少使用5年，后对病人心脏安全性等毒副作用相关的研究和数据，谢谢！',\n",
       "     'processed_text': '晚期  病人  长期  使用  至少  使用  病人  人心  心脏  安全  安全性  毒副  毒副作用  副作用  作用  相关  研究  数据'}}]}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = \"关于赫赛汀心脏毒性：1、临床 2、临床前\"\n",
    "\n",
    "results = es.search(index='index', body={'query': {'match':{\"text\": query}}}, size=10)\n",
    "hits = results['hits']['hits']\n",
    "results\n",
    "# for idx, res in enumerate(hits):\n",
    "#     print(str(idx+1) + \":  \" + res['_source']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
