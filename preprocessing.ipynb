{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import jieba\n",
    "import collections\n",
    "import pickle\n",
    "import codecs\n",
    "import mysql.connector as sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = sql.connect(host='rm-2zet5lw17as40fty28o.mysql.rds.aliyuncs.com',\n",
    "                            database='medo_master', \n",
    "                            user='snowball', \n",
    "                            password='MEDOsnow$%^&')\n",
    "# mesh_zh_df = pd.read_sql('SELECT translated FROM mesh_ref_copy1', con = db_connection)\n",
    "# mesh_zh_df.dropna(axis=0, inplace=True)\n",
    "# print(len(mesh_zh_df))\n",
    "# mesh_zh_list = mesh_zh_df['translated'].tolist()\n",
    "# mesh_zh_dict = []\n",
    "# for item in mesh_zh_list:\n",
    "#     mesh_zh_dict += item.split('，')\n",
    "# removed_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '', ' ']\n",
    "# mesh_zh_dict = [w for w in mesh_zh_dict if w not in removed_list]\n",
    "# mesh_zh_dict = list(set(mesh_zh_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71469\n"
     ]
    }
   ],
   "source": [
    "nsfc_data = pd.read_sql('SELECT summaryCh FROM nsfc_data', con = db_connection)\n",
    "nsfc_data.dropna(axis=0, inplace=True)\n",
    "print(len(nsfc_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, text in nsfc_data.iterrows():\n",
    "    if \"乳腺癌激酶\" in text['summaryCh']:\n",
    "        print(idx+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuyaqiang/software/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42886\n"
     ]
    }
   ],
   "source": [
    "mesh = pd.read_csv('./data/a.csv')\n",
    "mesh.dropna(axis=0, inplace=True, subset=['translated'])\n",
    "mesh_zh_dict = mesh['translated'].tolist()\n",
    "mesh_zh_dict = list(set(mesh_zh_dict))\n",
    "print(len(mesh_zh_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54609\n",
      "91563\n"
     ]
    }
   ],
   "source": [
    "chinese_word_dict = pickle.load(open('./dict data/chinese_word_dict.pickle', 'rb'))\n",
    "print(len(chinese_word_dict))\n",
    "chinese_word_dict += mesh_zh_dict\n",
    "chinese_word_dict = list(set(chinese_word_dict))\n",
    "print(len(chinese_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict('./dict data/chinese_word_dict.txt')\n",
    "stopwords = [line.strip() for line in codecs.open('./stopwords-zh.txt', 'r', encoding='utf8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_question:  1970\n",
      "all_question:  1656\n"
     ]
    }
   ],
   "source": [
    "# all_question = pd.read_csv('./data/description.csv')\n",
    "Herceptin_question = pd.read_excel('./data/Herceptin.xlsx')\n",
    "# all_question = pd.read_excel('./data/Herceptin_funding_filtered.xlsx')\n",
    "# all_question = pd.read_excel('./data/Herceptin_patient_filtered.xlsx')\n",
    "Kadcyla_question = pd.read_excel('./data/Kadcyla.xlsx')\n",
    "Perjeta_1_question = pd.read_excel('./data/Perjeta_1.xlsx')\n",
    "Perjeta_2_question = pd.read_excel('./data/Perjeta_2.xlsx')\n",
    "Tecentriq_question = pd.read_excel('./data/Tecentriq.xlsx')\n",
    "Xeloda_question = pd.read_excel('./data/Xeloda.xlsx')\n",
    "No_product_question = pd.read_excel('./data/No_product_merged.xlsx')\n",
    "\n",
    "all_question = pd.concat([Herceptin_question, Kadcyla_question, Perjeta_1_question, Perjeta_2_question, Tecentriq_question, Xeloda_question, No_product_question])\n",
    "print('all_question: ', len(all_question))\n",
    "all_question.head(5)\n",
    "\n",
    "all_question.dropna(axis=0, inplace=True, subset=['Description'])\n",
    "all_question.isna().sum()\n",
    "\n",
    "print('all_question: ', len(all_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.analyse.textrank as textrank\n",
    "\n",
    "def keyword_extract(text, word_dict):\n",
    "#     text = list(jieba.cut(text, cut_all=False))\n",
    "#     text = list(jieba.cut_for_search(text))\n",
    "#     text = [w for w in text if w in word_dict]\n",
    "    print(textrank(text))\n",
    "    return \" \".join(textrank(text))\n",
    "\n",
    "# 去除所有“[]”内的文本\n",
    "def remove_special_string(text):\n",
    "    text = re.sub(r'\\[[^]]*\\]', '', text)\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'（[^）]*\\）', '', text)\n",
    "    text = re.sub(r'\\<[^>]*\\>', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text, stopwords):\n",
    "    keywords = text.split()\n",
    "    keywords = [w for w in keywords if w not in stopwords]\n",
    "    return \"  \".join(keywords)\n",
    "\n",
    "all_question['Description'] = all_question.Description.apply(lambda x: remove_special_string(x))\n",
    "all_question['KeyWords'] = all_question.Description.apply(lambda x: keyword_extract(x, chinese_word_dict))\n",
    "# all_question['KeyWords'] = all_question.KeyWords.apply(lambda x: remove_stopwords(x, stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_extract(\"关于拉帕替尼加希罗达的临床试验\", chinese_word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "for idx, row in all_question.iterrows():\n",
    "    if \"关于拉帕替尼加希罗达的临床试验\" in row['Description']:\n",
    "        print('111'+row['KeyWords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656\n",
      "1656\n"
     ]
    }
   ],
   "source": [
    "description_list = all_question['Description'].tolist()\n",
    "keywords_list = all_question['KeyWords'].tolist()\n",
    "print(len(description_list))\n",
    "print(len(keywords_list))\n",
    "write_list = []\n",
    "for idx, item in enumerate(description_list):\n",
    "    line = '原文本： ' + item + '\\n' + '关键词： ' + keywords_list[idx] + '\\n\\n'\n",
    "    write_list.append(line)\n",
    "\n",
    "f_sourcetext_and_keywords = open('text_keywords_3.txt', 'w')\n",
    "f_sourcetext_and_keywords.writelines(write_list)\n",
    "f_sourcetext_and_keywords.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"乳腺癌激酶\" in chinese_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563\n",
      "563\n",
      "文献查询 Dear：麻烦帮忙查一下以下的文献1，J Natl Cancer Inst. 2018 Jun 1;110(6):560-567. doi: 10.1093/jnci/djy018 2，JAMA Oncol. 2018 Sep 1;4(9):1207-1213. doi: 10.1001/jamaoncol.2018.1436 3，Ann Surg. 2017 Jul 24. doi: 10.1097/SLA.0000000000002439 4，Ann Surg. 2018 May;267(5):946-951. doi: 10.1097/SLA.0000000000002313 5，JAMA Surg. 2017 Jul 1;152(7):665-670. doi: 10.1001/jamasurg.2017.0562非常感谢\n"
     ]
    }
   ],
   "source": [
    "case_number_list = []\n",
    "description_list = []\n",
    "for idx, row in No_product_question.iterrows():\n",
    "    if str(row['Case Number']) != 'nan':\n",
    "        case_number_list.append(row['Case Number'])\n",
    "        description_list.append(str(row['Description']))\n",
    "    else:\n",
    "        description_list[-1] = description_list[-1] + \" \" + str(row['Description'])\n",
    "print(len(case_number_list))\n",
    "print(len(description_list))\n",
    "print(description_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list = list(zip(case_number_list, description_list))\n",
    "print(len(row_list))\n",
    "row_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_product_question_processed = pd.DataFrame(row_list, columns=['Case Number', 'Description'])\n",
    "No_product_question_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_product_question_processed.to_excel(\"./data/No_product_merged.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_excel(\"./data/Herceptin_filtered.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number                400\n",
       "Contact Type               402\n",
       "Contact Channel            402\n",
       "Response Channel           402\n",
       "Enquiry Classification     402\n",
       "Subject                    402\n",
       "Description                332\n",
       "Product                    402\n",
       "Response                    95\n",
       "Unnamed: 9                1157\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.dropna(axis=0, inplace=True, subset=['Case Number', 'Contact Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number                 0\n",
       "Contact Type                0\n",
       "Contact Channel             0\n",
       "Response Channel            0\n",
       "Enquiry Classification      0\n",
       "Subject                     0\n",
       "Description                 0\n",
       "Product                     0\n",
       "Response                    0\n",
       "Unnamed: 9                756\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop(all_data[all_data['Contact Type'] == 'Patient'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.to_excel('./data/Herceptin_patient_filtered.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_data = pd.read_csv('./mesh_ref_copy1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911261\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000065</th>\n",
       "      <th>anatomy category</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000066</td>\n",
       "      <td>organisms category</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000067</td>\n",
       "      <td>diseases category</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000068</td>\n",
       "      <td>chemicals and drugs category</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000069</td>\n",
       "      <td>analytical, diagnostic and therapeutic techniq...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000070</td>\n",
       "      <td>psychiatry and psychology category</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1000065                                   anatomy category  A\n",
       "0  1000066                                 organisms category  B\n",
       "1  1000067                                  diseases category  C\n",
       "2  1000068                       chemicals and drugs category  D\n",
       "3  1000069  analytical, diagnostic and therapeutic techniq...  E\n",
       "4  1000070                 psychiatry and psychology category  F"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(mesh_data))\n",
    "mesh_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_zh(string):\n",
    "    return all('\\u4e00' <= char <= '\\u9fff' for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_word_dict = []\n",
    "for idx,row in mesh_data.iterrows():\n",
    "    if is_zh(row['anatomy category']):\n",
    "        chinese_word_dict.append(row['anatomy category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44223\n"
     ]
    }
   ],
   "source": [
    "print(len(chinese_word_dict))\n",
    "# chinese_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimc_data = pd.read_csv('./mimc_not_matched.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59002\n"
     ]
    }
   ],
   "source": [
    "for idx, row in mimc_data.iterrows():\n",
    "    chinese_word_dict.append(row['zh'])\n",
    "print(len(chinese_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6555\n"
     ]
    }
   ],
   "source": [
    "cnkd_data = pd.read_csv('./cnkd_not_matched.csv')\n",
    "print(len(cnkd_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65557\n"
     ]
    }
   ],
   "source": [
    "for idx, row in cnkd_data.iterrows():\n",
    "    chinese_word_dict.append(row['zh'])\n",
    "print(len(chinese_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_word_dict = list(set(chinese_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54609"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chinese_word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'赫赛汀' in chinese_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./chinese_word_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(chinese_word_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_chinese_word_dict = open('./dict data/chinese_word_dict.txt', 'w')\n",
    "write_list = [word+\"\\n\" for word in chinese_word_dict]\n",
    "f_chinese_word_dict.writelines(write_list)\n",
    "f_chinese_word_dict.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
