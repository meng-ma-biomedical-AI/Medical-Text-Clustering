{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "import re\n",
    "import codecs\n",
    "import jieba\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import IndicesClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host':'localhost','port':9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_idx = IndicesClient(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"acknowledged\":true,\"shards_acknowledged\":true,\"index\":\"main_idx\"}\n"
     ]
    }
   ],
   "source": [
    "a = os.popen('''\n",
    "curl -X PUT 'localhost:9200/main_idx' -d '\n",
    "{\n",
    "  \"mappings\": {\n",
    "    \"docs\": {\n",
    "      \"properties\": {\n",
    "        \"pure_text\": {\n",
    "          \"type\": \"text\",\n",
    "          \"analyzer\": \"ik_max_word\",\n",
    "          \"search_analyzer\": \"ik_max_word\"\n",
    "        },\n",
    "        \"processed_text\": {\n",
    "          \"type\": \"text\",\n",
    "          \"analyzer\": \"ik_max_word\",\n",
    "          \"search_analyzer\": \"ik_max_word\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}'\n",
    "''').read()\n",
    "for line in a.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_index\":\"main_idx\",\"_type\":\"docs\",\"_id\":\"1\",\"_version\":1,\"result\":\"created\",\"_shards\":{\"total\":2,\"successful\":1,\"failed\":0},\"created\":true}\n"
     ]
    }
   ],
   "source": [
    "# res1 = os.popen('''\n",
    "# curl -X PUT 'localhost:9200/main_idx/docs/1' -d '\n",
    "# {\n",
    "#     \"pure_text\": \"中华人民共和国国歌\",\n",
    "#     \"processed_text\": \"中华 人民 共和国 国歌\"\n",
    "# }'\n",
    "# ''').read()\n",
    "# for line in res1.split('\\n'):\n",
    "#     print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"took\":1,\"timed_out\":false,\"_shards\":{\"total\":5,\"successful\":5,\"skipped\":0,\"failed\":0},\"hits\":{\"total\":1,\"max_score\":0.25811607,\"hits\":[{\"_index\":\"main_idx\",\"_type\":\"docs\",\"_id\":\"1\",\"_score\":0.25811607,\"_source\":\n",
      "{\n",
      "    \"pure_text\": \"中华人民共和国国歌\",\n",
      "    \"processed_text\": \"中华 人民 共和国 国歌\"\n",
      "}}]}}\n"
     ]
    }
   ],
   "source": [
    "# res = os.popen('''\n",
    "# curl 'localhost:9200/main_idx/docs/_search'  -d '\n",
    "# {\n",
    "#   \"query\" : { \"match\" : { \"pure_text\" : \"中华人民共和国\" }}\n",
    "# }'\n",
    "# ''').read()\n",
    "# for line in res.split('\\n'):\n",
    "#     print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# es_idx.exists(index='text_search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_idx.delete(index='_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_question:  1407\n",
      "all_question:  1093\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Description</th>\n",
       "      <th>KeyWords</th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1420656.0</td>\n",
       "      <td>赫赛汀  配了之后结冰了， 能否继续使用。</td>\n",
       "      <td>赫赛汀 使用</td>\n",
       "      <td>赫赛汀  配  之后  结冰  继续  使用</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1423956.0</td>\n",
       "      <td>赫赛汀粉末形状如何？患者保存的赫赛汀的稀释液出现结冰情况，是否能否使用</td>\n",
       "      <td>无 赫赛汀 使用 患者</td>\n",
       "      <td>赫赛汀  粉末  形状  保存  赫赛汀  稀释  稀释液  出现  结冰  冰情  情况 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1434184.0</td>\n",
       "      <td>请帮忙查一些赫赛汀与血栓栓塞方面的数据和文献</td>\n",
       "      <td>查 血栓 无 赫赛汀 栓塞 血栓栓塞 文献</td>\n",
       "      <td>帮忙  查  赫赛汀  血栓  血栓栓塞  栓塞  方面  数据  和文  文献</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1436011.0</td>\n",
       "      <td>拿到的赫赛汀呈现块状是否正常</td>\n",
       "      <td>赫赛汀 正常</td>\n",
       "      <td>拿到  赫赛汀  呈现  块状  是否  正常</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1438071.0</td>\n",
       "      <td>常规配置和保存的赫赛汀复溶后的溶液保存在-度的情况下，现出现浑浊情况，能否使用</td>\n",
       "      <td>下 使用 现 赫赛汀 配置 溶液</td>\n",
       "      <td>常规  配置  保存  赫赛汀  复  溶  溶液  保存  存在  度  情况  现出  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case Number                              Description  \\\n",
       "0    1420656.0                    赫赛汀  配了之后结冰了， 能否继续使用。   \n",
       "1    1423956.0      赫赛汀粉末形状如何？患者保存的赫赛汀的稀释液出现结冰情况，是否能否使用   \n",
       "2    1434184.0                   请帮忙查一些赫赛汀与血栓栓塞方面的数据和文献   \n",
       "3    1436011.0                           拿到的赫赛汀呈现块状是否正常   \n",
       "4    1438071.0  常规配置和保存的赫赛汀复溶后的溶液保存在-度的情况下，现出现浑浊情况，能否使用   \n",
       "\n",
       "                KeyWords                                          Processed  \n",
       "0                 赫赛汀 使用                             赫赛汀  配  之后  结冰  继续  使用  \n",
       "1            无 赫赛汀 使用 患者  赫赛汀  粉末  形状  保存  赫赛汀  稀释  稀释液  出现  结冰  冰情  情况 ...  \n",
       "2  查 血栓 无 赫赛汀 栓塞 血栓栓塞 文献           帮忙  查  赫赛汀  血栓  血栓栓塞  栓塞  方面  数据  和文  文献  \n",
       "3                 赫赛汀 正常                            拿到  赫赛汀  呈现  块状  是否  正常  \n",
       "4       下 使用 现 赫赛汀 配置 溶液  常规  配置  保存  赫赛汀  复  溶  溶液  保存  存在  度  情况  现出  ...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_question = pd.read_csv('./data/description.csv')\n",
    "Herceptin_question = pd.read_excel('./data/Herceptin.xlsx')\n",
    "# all_question = pd.read_excel('./data/Herceptin_funding_filtered.xlsx')\n",
    "# all_question = pd.read_excel('./data/Herceptin_patient_filtered.xlsx')\n",
    "Kadcyla_question = pd.read_excel('./data/Kadcyla.xlsx')\n",
    "Perjeta_1_question = pd.read_excel('./data/Perjeta_1.xlsx')\n",
    "Perjeta_2_question = pd.read_excel('./data/Perjeta_2.xlsx')\n",
    "Tecentriq_question = pd.read_excel('./data/Tecentriq.xlsx')\n",
    "Xeloda_question = pd.read_excel('./data/Xeloda.xlsx')\n",
    "\n",
    "all_question = pd.concat([Herceptin_question, Kadcyla_question, Perjeta_1_question, Perjeta_2_question, Tecentriq_question, Xeloda_question])\n",
    "print('all_question: ', len(all_question))\n",
    "all_question.head(5)\n",
    "\n",
    "all_question.dropna(axis=0, inplace=True, subset=['Description'])\n",
    "all_question.isna().sum()\n",
    "\n",
    "print('all_question: ', len(all_question))\n",
    "\n",
    "jieba.load_userdict('./dict data/chinese_word_dict.txt')\n",
    "chinese_word_dict = pickle.load(open('./dict data/chinese_word_dict.pickle', 'rb'))\n",
    "stopwords = [line.strip() for line in codecs.open('./stopwords-zh.txt', 'r', encoding='utf8').readlines()]\n",
    "\n",
    "def keyword_extract(text, word_dict):\n",
    "#     text = list(jieba.cut(text, cut_all=False))\n",
    "    text = list(jieba.cut_for_search(text))\n",
    "    union_text = list(set(text).intersection(set(word_dict)))\n",
    "    return \" \".join(union_text)\n",
    "\n",
    "all_question['KeyWords'] = all_question.Description.apply(lambda x: keyword_extract(x, chinese_word_dict))\n",
    "\n",
    "# 去除所有“[]”内的文本\n",
    "def remove_special_string(text):\n",
    "    text = re.sub(r'\\[[^]]*\\]', '', text)\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'（[^）]*\\）', '', text)\n",
    "    text = re.sub(r'\\<[^>]*\\>', '', text)\n",
    "    text = re.sub(r'[0-9]*', '', text)\n",
    "#     text = re.sub('患者', '', text)\n",
    "#     text = re.sub('家属', '', text)\n",
    "#     text = re.sub('咨询', '', text)\n",
    "#     text = re.sub('询问', '', text)\n",
    "    return text\n",
    "def remove_stopwords(text, stopwords):\n",
    "    text_cutted = jieba.cut(text, cut_all=True)\n",
    "    text_removed = []\n",
    "    for word in text_cutted:\n",
    "        if word in stopwords or word.strip()==\"\":\n",
    "            continue\n",
    "        text_removed.append(word)\n",
    "    return \"  \".join(text_removed)\n",
    "\n",
    "all_question['Description'] = all_question.Description.apply(lambda x: remove_special_string(x))\n",
    "all_question['Processed'] = all_question.Description.apply(lambda x: remove_special_string(x))\n",
    "all_question['Processed'] = all_question.Processed.apply(lambda x: remove_stopwords(x, stopwords))\n",
    "all_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 赫赛汀抑制二聚体形成的临床研究\n"
     ]
    }
   ],
   "source": [
    "for idx, row in all_question.iterrows():\n",
    "    if '二聚体' in row['Description']:\n",
    "        print(row['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093\n",
      "{'pure_text': '赫赛汀  配了之后结冰了， 能否继续使用。', 'processed_text': '赫赛汀 使用'}\n"
     ]
    }
   ],
   "source": [
    "doc_list = []\n",
    "for idx,row in all_question.iterrows():\n",
    "    doc = {\"pure_text\": row['Description'], \"processed_text\": row['KeyWords']}\n",
    "    doc_list.append(doc)\n",
    "print(len(doc_list))\n",
    "print(doc_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_index\":\"ik_test\",\"_type\":\"docs\",\"_id\":\"1\",\"_version\":3,\"result\":\"updated\",\"_shards\":{\"total\":2,\"successful\":1,\"failed\":0},\"created\":false}\n"
     ]
    }
   ],
   "source": [
    "res1 = os.popen('''\n",
    "curl -X PUT 'localhost:9200/main_idx/docs/1' -d '\n",
    "{\n",
    "    \"pure_text\": \"中华人民共和国国歌\",\n",
    "    \"processed_text\": \"中华 人民 共和国 国歌\"\n",
    "}'\n",
    "''').read()\n",
    "for line in res1.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in doc_list:\n",
    "    temp = os.popen('''\n",
    "    curl -X POST 'localhost:9200/main_idx/docs' -d '\n",
    "    {}\n",
    "    '\n",
    "    '''.format(str(doc).replace(\"\\\"\", \"\\'\").replace(\"\\'\", \"\\\"\"))).read()\n",
    "    for line in temp.split('\\n'):\n",
    "        print(line)\n",
    "        \n",
    "#     print('''\n",
    "#     curl -X PUT 'localhost:9200/ik_test/docs/{}' -d '\n",
    "#     {}\n",
    "#     '\n",
    "#     '''.format(str(idx), str(doc_list[idx]).replace(\"\\\"\", \"\\'\").replace(\"\\'\", \"\\\"\")))\n",
    "    \n",
    "# curl -X PUT 'localhost:9200/ik_test/docs/1' -d '\n",
    "# {\n",
    "#     \"content\": \"中华人民共和国国歌\"\n",
    "# }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = os.popen('''\n",
    "curl 'localhost:9200/main_idx/docs/_search?pretty=true'  -d '\n",
    "{\n",
    "  \"query\" : { \"match\" : { \"processed_text\" : \"关于赫赛汀心脏毒性：1、临床 2、临床前\" }}\n",
    "}'\n",
    "''').read()\n",
    "for line in res.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(doc_list)):\n",
    "    es.index(index='text_search', id=idx, body=doc_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:   赫赛汀抑制二聚体形成的临床研究\n",
      "2:   麻烦查询“BOLERO-”临床研究的全文，如果没有全文，请尽量提供更多的该研究的信息，谢谢\n",
      "3:  ，帕捷特什么时候上市，价格是多少，有无临床研究。\n",
      "4:   需要罗氏帕妥珠单抗晚期一线，辅助，新辅助临床研究发表的原文。\n",
      "5:   乳腺癌晚期一线TX对比TE的临床研究\n",
      "6:  你好：请在clinicaltrial.gov网站上查询是否已经有这样的临床设计注册：关于HER阳性新辅助未达pCR，然后分组一组H，一组HX。H：赫赛汀；HX：赫赛汀联合希罗达。想自行发起这样的临床研究，需要先查询是否已经有类似的临床已经注册，谢谢！\n",
      "7:   请在clinicaltrial.gov网站上查询是否已经有这样的临床设计注册：关于HER阳性新辅助未达pCR，然后分组一组H，一组HX。H：赫赛汀；HX：赫赛汀联合希罗达。医生想自行发起这样的临床研究，想请我们先查询是否已经有类似的临床已经注册，谢谢！\n",
      "8:   卡培联合AI，从体外实验到临床，研究文献\n",
      "9:   您好，请帮忙查询晚期乳腺癌一线治疗使用赫赛汀联合卡培他滨的临床研究，全文，谢谢\n",
      "10:  卡培他滨研发早期用于晚期乳腺癌临床研究文献\n",
      "11:   请问现有有关帕捷特的临床研究中有紫杉醇三周方案的吗？如果有，请提供研究以紫杉的具体用法。如果没有，麻烦解释原因，谢谢！\n",
      "12:   需要一些转移性乳腺癌，xt-x化疗的相关的临床研究和资料。谢谢。\n",
      "13:  ，帕托珠单抗在晚期乳腺癌的相关临床研究\n",
      "14:   晚期乳腺癌XT方案和GP方案对比的临床研究，XT方案与其它联合方案的临床研究\n",
      "15:   请查询帕妥珠单抗用于早期乳腺癌新辅助，辅助以及晚期乳腺癌的临床研究原文文献。\n",
      "16:   希罗达在晚期乳腺癌使用的文献及临床研究，年的NCCN乳腺癌诊疗指南，年ASCO乳腺癌诊疗指南，能否麻烦把手头上有的发给我呢？谢谢\n",
      "17:   请帮忙在https://clinicaltrials.gov/网站进行查询，是否有氟纬司琼联合卡培他滨节拍化疗应用在晚期乳腺癌的临床研究注册，如果有，请提供注册的详细内容，谢谢\n",
      "18:   麻烦帮我查询早期乳腺癌新辅助治疗中含有卡培他滨的所有化疗方案的临床研究原文，谢谢\n",
      "19:   三阴性乳腺癌用卡培辅助一年的临床研究有哪个？是否有具体的文献，谢谢\n",
      "20:   关于tdm的临床试验\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"赫赛汀抑制二聚体形成的临床研究\"\n",
    "\n",
    "# processed_text  pure_text\n",
    "results = es.search(index='main_idx', body=\n",
    "# {\n",
    "#   \"query\" : { \"match\" : { \"pure_text\" : query }}\n",
    "# }\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\":     { \"match\": { \"processed_text\": query }},\n",
    "      \"should\":   { \"match\": { \"pure_text\": \"赫赛汀\" }}\n",
    "    }\n",
    "  }\n",
    "}\n",
    ",size=20)\n",
    "hits = results['hits']['hits']\n",
    "# results\n",
    "for idx, res in enumerate(hits):\n",
    "    print(str(idx+1) + \":  \" + res['_source']['pure_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-65-f0049b57d55b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-65-f0049b57d55b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1:  关于赫赛汀心脏毒性：1、临床 2、临床前\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "1:  关于赫赛汀心脏毒性：1、临床 2、临床前\n",
    "2:  [Wechat] 临床上赫赛汀q3W和qW用法，在心脏毒性方面，哪个频率心脏毒性小些？相关研究？\n",
    "3:  [Wechat] 关于tdm1的临床试验\n",
    "4:  [Wechat] 请帮忙查询以下临床研究的全文以供学习，谢谢！ 1、XT对比GT在晚期乳腺癌化疗中的临床研究原文；重点关注毒性的对比。至少有两个相关研究。X：希罗达，T：多西他赛/多西紫杉醇，G：吉西他滨  2、GP（吉西他滨联合紫杉醇）用于晚期乳腺癌化疗的临床研究全文。\n",
    "5:  [Wechat] 赫赛汀对于心脏毒性的相关文献以及处理方法\n",
    "6:  [Wechat] 赫赛汀，放疗，心脏毒性相关文献\n",
    "7:  [Wechat] 关于拉帕替尼加希罗达的临床试验\n",
    "8:  [Wechat] 你好，我要问询关于帕捷特使用的问题，目前临床有一位乳腺癌患者体重30kg，帕捷特应该怎么使用，临床老师担心，针对这种特殊患者是否需要减量，比如6周一个疗程\n",
    "9:  [Wechat] 都是关于希罗达在晚期乳腺癌的研究：1.多西他赛联合希罗达对比多西他赛单药，的3期临床研究原文（中文）2.希罗达 多西他赛vs 表柔比星 多西他赛的临床研究原文（中文）3.希罗达 多西他赛 vs 吉西他滨 多西他赛的临床研究原文（中文）谢谢您\n",
    "10:  赫赛汀在心脏毒性方面的研究数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "赫赛汀\n",
      "抑制\n",
      "二聚体\n",
      "聚\n",
      "体形\n",
      "体\n",
      "形成\n",
      "形\n",
      "成\n",
      "临床研究\n",
      "临床\n",
      "床\n",
      "研究\n",
      "究\n"
     ]
    }
   ],
   "source": [
    "tokens_res = es_idx.analyze(index='main_idx', body={\n",
    "    \"analyzer\": \"ik_max_word\",\n",
    "#     \"analyzer\": \"ik_smart\",\n",
    "    \"text\" : \"赫赛汀抑制二聚体形成的临床研究\"\n",
    "})\n",
    "for token in tokens_res['tokens']:\n",
    "    print(token['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
